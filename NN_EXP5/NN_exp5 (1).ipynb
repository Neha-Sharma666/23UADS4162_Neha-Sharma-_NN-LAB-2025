{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshape for CNN input\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Define the model\n",
        "def create_model(optimizer='adam', filter_size=5, reg_strength=0.001):\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (filter_size, filter_size), activation='relu', input_shape=(28, 28, 1), kernel_regularizer=regularizers.l2(reg_strength)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(64, (filter_size, filter_size), activation='relu', kernel_regularizer=regularizers.l2(reg_strength)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(reg_strength)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(reg_strength)),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Parameters\n",
        "optimizer_choice = 'adam'\n",
        "filter_size_choice = 5\n",
        "reg_strength_choice = 0.001\n",
        "batch_size_choice = 64\n",
        "epochs_choice = 15\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, min_lr=1e-5)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# Build and train model\n",
        "print(f\"\\nTraining Model: filter_size={filter_size_choice}, reg_strength={reg_strength_choice}, \"\n",
        "      f\"batch_size={batch_size_choice}, optimizer='{optimizer_choice}'\\n\")\n",
        "\n",
        "model = create_model(optimizer=optimizer_choice,\n",
        "                     filter_size=filter_size_choice,\n",
        "                     reg_strength=reg_strength_choice)\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=epochs_choice,\n",
        "    batch_size=batch_size_choice,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,  # Shows output for each epoch\n",
        "    callbacks=[reduce_lr, early_stopping, checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Final Summary\n",
        "print(\"\\nFinal Training Summary:\")\n",
        "print(f\"Epochs Completed: {len(history.history['loss'])}\")\n",
        "print(f\"Optimizer        : {optimizer_choice}\")\n",
        "print(f\"Filter Size      : {filter_size_choice}\")\n",
        "print(f\"Reg Strength     : {reg_strength_choice}\")\n",
        "print(f\"Batch Size       : {batch_size_choice}\")\n",
        "print(f\"Test Accuracy    : {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKdr_0Cag0Vc",
        "outputId": "97467c8e-50b2-470b-b92e-e7356834c220"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Model: filter_size=5, reg_strength=0.001, batch_size=64, optimizer='adam'\n",
            "\n",
            "Epoch 1/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7730 - loss: 0.8959 - val_accuracy: 0.8509 - val_loss: 0.5985 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8771 - loss: 0.5153 - val_accuracy: 0.8461 - val_loss: 0.5385 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.4329 - val_accuracy: 0.8859 - val_loss: 0.4281 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.3924 - val_accuracy: 0.8636 - val_loss: 0.5007 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.3802 - val_accuracy: 0.8838 - val_loss: 0.4363 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9082 - loss: 0.3690 - val_accuracy: 0.8942 - val_loss: 0.4047 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.3587 - val_accuracy: 0.8970 - val_loss: 0.3934 - learning_rate: 0.0010\n",
            "Epoch 8/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9137 - loss: 0.3494 - val_accuracy: 0.8622 - val_loss: 0.4792 - learning_rate: 0.0010\n",
            "Epoch 9/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.3442 - val_accuracy: 0.8856 - val_loss: 0.4452 - learning_rate: 0.0010\n",
            "Epoch 10/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.3347 - val_accuracy: 0.8900 - val_loss: 0.4272 - learning_rate: 0.0010\n",
            "Epoch 11/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.2951 - val_accuracy: 0.9181 - val_loss: 0.3327 - learning_rate: 3.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9487 - loss: 0.2452 - val_accuracy: 0.9224 - val_loss: 0.3233 - learning_rate: 3.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9536 - loss: 0.2241 - val_accuracy: 0.9191 - val_loss: 0.3310 - learning_rate: 3.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9563 - loss: 0.2080 - val_accuracy: 0.9215 - val_loss: 0.3297 - learning_rate: 3.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.1948 - val_accuracy: 0.9084 - val_loss: 0.3701 - learning_rate: 3.0000e-04\n",
            "\n",
            "Final Training Summary:\n",
            "Epochs Completed: 15\n",
            "Optimizer        : adam\n",
            "Filter Size      : 5\n",
            "Reg Strength     : 0.001\n",
            "Batch Size       : 64\n",
            "Test Accuracy    : 0.9155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RGlkilIKGBVt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}